{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillermoda/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import base64\n",
    "from requests import post, get\n",
    "import csv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv(\"CID\")\n",
    "client_secret = os.getenv(\"SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token():\n",
    "    auth_string = client_id + \":\" + client_secret\n",
    "    auth_bytes = auth_string.encode(\"utf-8\")\n",
    "    auth_base64 = str(base64.b64encode(auth_bytes), \"utf-8\")\n",
    "\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Basic \" + auth_base64,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "\n",
    "    result = post(url, headers=headers, data=data)\n",
    "    json_result = json.loads(result.content)\n",
    "    token = json_result[\"access_token\"]\n",
    "\n",
    "    return token\n",
    "\n",
    "def get_auth_header(token):\n",
    "    return {\"Authorization\": \"Bearer \" + token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def getRandomSearch():\n",
    "    # Una lista de todos los caracteres que se pueden elegir.\n",
    "    characters = 'abcdefghijklmnopqrstuvwxyz1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZñÑ ¿?:;-,><&/()=!¡|@#$\"'\n",
    "    \n",
    "    # Obtiene un carácter aleatorio de la cadena de caracteres.\n",
    "    randomCharacter = random.choice(characters)\n",
    "    randomSearch = ''\n",
    "    \n",
    "    # Coloca el carácter comodín al principio, o al principio y al final, de forma aleatoria.\n",
    "    if random.randint(0, 1) == 0:\n",
    "        randomSearch = randomCharacter + '%'\n",
    "    else:\n",
    "        randomSearch = '%' + randomCharacter + '%'\n",
    "    \n",
    "    return randomSearch\n",
    "\n",
    "def search_banch_of_tracks(randomSearch, randomOffset, limit=50):\n",
    "    token = get_token()\n",
    "    auth_header = get_auth_header(token)\n",
    "    url = \"https://api.spotify.com/v1/search\"\n",
    "    params = {\n",
    "        \"q\": randomSearch,\n",
    "        \"type\": \"track\",\n",
    "        \"limit\": limit,\n",
    "        \"offset\": randomOffset,\n",
    "    }\n",
    "    response = get(url, headers=auth_header, params=params)\n",
    "    json_response = json.loads(response.content)\n",
    "    return json_response\n",
    "\n",
    "def write_csv(json_response, file):\n",
    "    try:\n",
    "        new_tracks_df = pd.DataFrame(json_response[\"tracks\"][\"items\"])\n",
    "        with open(file, \"a\") as f:\n",
    "            new_tracks_df.to_csv(f)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "def depurar_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "def get_several_tracks(file, iterations=1000):\n",
    "    for i in range(0, iterations):\n",
    "        randomSearch = getRandomSearch()\n",
    "        randomOffset = random.randint(0, 1000)\n",
    "        print(f'Iteration {i} - Search: {randomSearch} - Offset: {randomOffset}')\n",
    "        json_response = search_banch_of_tracks(randomSearch, randomOffset)\n",
    "        write_csv(json_response, file)\n",
    "    depurar_csv(file)\n",
    "    \n",
    "    \n",
    "def get_track_features(df):\n",
    "    token = get_token()\n",
    "    auth_header = get_auth_header(token)\n",
    "    url = \"https://api.spotify.com/v1/audio-features\"\n",
    "    track_ids = df[\"id\"].tolist()\n",
    "    track_features = []\n",
    "    for i in range(0, len(track_ids), 100):\n",
    "        try:\n",
    "            params = {\"ids\": \",\".join(track_ids[i:i+100])}\n",
    "            response = get(url, headers=auth_header, params=params)\n",
    "            json_response = json.loads(response.content)\n",
    "            if \"audio_features\" in json_response:\n",
    "                track_features += json_response[\"audio_features\"]\n",
    "                #add the json the id of each track\n",
    "                for j in range(len(json_response[\"audio_features\"])):\n",
    "                    try:\n",
    "                        track_features[-1-j][\"id\"] = track_ids[i+99-j]\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                print(f\"No audio features found in response: {json_response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {i} to {i+100}: {str(e)}\")\n",
    "            continue\n",
    "    return track_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_several_tracks(file=\"db_extract.csv\", iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depurar_csv(file=\"db_extract.csv\")\n",
    "df = pd.read_csv(\"db_extract.csv\")\n",
    "track_features = get_track_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all track features have id, if not, erase it\n",
    "track_features_aux = {\"track\": []}\n",
    "for track in track_features:\n",
    "    try:\n",
    "        if \"id\" not in track:\n",
    "            track_features.remove(track)\n",
    "        else:\n",
    "            track_features_aux[\"track\"].append(track)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_features = pd.DataFrame(track_features_aux[\"track\"])\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge two dataframes with the same id\n",
    "df_merged = pd.merge(df, df_features, on=\"id\")\n",
    "#if acousticness is in blank, erase that row\n",
    "df_merged = df_merged[df_merged[\"acousticness\"].notna()]\n",
    "df_merged.to_csv(\"db_extract_features_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are not needed [Unnamed: 0, disc_number, external_ids, external_urls, href, is_local, prewiew_url, track_number, type_x, uri_x, type_y, uri_y, track_href, analysis_url, duration_ms_y, time_signature]\n",
    "df_merged.drop(columns=[\"Unnamed: 0\", \"disc_number\", \"external_ids\", \"external_urls\", \"href\", \"is_local\", \"preview_url\", \"track_number\", \"type_x\", \"uri_x\", \"type_y\", \"uri_y\", \"track_href\", \"analysis_url\", \"duration_ms_y\", \"time_signature\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column duration_ms_x to duration_ms\n",
    "df_merged.rename(columns={\"duration_ms_x\": \"duration_ms\"}, inplace=True)\n",
    "df_merged.to_csv(\"db_extract_features_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/p7vxpgjs6hx87zfr9xd7gwz40000gp/T/ipykernel_59430/3946289955.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_markets.drop(columns=[\"Unnamed: 0\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#ckeck if 'ES' is in available markets, if not, erase that row\n",
    "df_merged = pd.read_csv(\"db_extract_features_merged.csv\")\n",
    "df_markets = df_merged[df_merged[\"available_markets\"].str.contains(\"ES\")]\n",
    "df_markets.set_index(\"id\", inplace=True)\n",
    "df_markets.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df_markets.to_csv(\"db_extract_features_merged_markets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"db_extract_features_merged_markets.csv\")\n",
    "df.drop(columns=[\"available_markets\"], inplace=True)\n",
    "df.to_csv(\"db_extract_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"db_extract_final.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "import ast\n",
    "\n",
    "def get_artists(json_str):\n",
    "    l = []\n",
    "    json_str = ast.literal_eval(json_str)\n",
    "    for artist in json_str:\n",
    "        l.append(artist['name'])\n",
    "    return l\n",
    "\n",
    "df['artists'] = [get_artists(json_str) for json_str in df['artists']]\n",
    "df['album'] = [ast.literal_eval(json_str)['name'] for json_str in df['album']]\n",
    "\n",
    "df.to_csv(\"db_extract_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
